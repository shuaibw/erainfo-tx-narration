{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Transaction_Naration_Data_Set.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['AC_ID'] = pd.Categorical(df['AC_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC_ID</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>DOC_DATE</th>\n",
       "      <th>NARATION</th>\n",
       "      <th>DR_CR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22546758.00</td>\n",
       "      <td>22546758.00</td>\n",
       "      <td>22546758</td>\n",
       "      <td>22545735</td>\n",
       "      <td>22546758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2887759.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "      <td>128603</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1863495.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28-DEC-22</td>\n",
       "      <td>Cash Withdrawal From A/C No.:</td>\n",
       "      <td>Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>44975.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740727</td>\n",
       "      <td>2359719</td>\n",
       "      <td>13871120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20755.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>82347.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>600.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>41500000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AC_ID      AMOUNT   DOC_DATE                        NARATION   \n",
       "count  22546758.00 22546758.00   22546758                        22545735  \\\n",
       "unique  2887759.00         NaN        180                          128603   \n",
       "top     1863495.00         NaN  28-DEC-22  Cash Withdrawal From A/C No.:    \n",
       "freq      44975.00         NaN     740727                         2359719   \n",
       "mean           NaN    20755.28        NaN                             NaN   \n",
       "std            NaN    82347.50        NaN                             NaN   \n",
       "min            NaN        0.01        NaN                             NaN   \n",
       "25%            NaN      600.00        NaN                             NaN   \n",
       "50%            NaN     1500.00        NaN                             NaN   \n",
       "75%            NaN     7000.00        NaN                             NaN   \n",
       "max            NaN 41500000.00        NaN                             NaN   \n",
       "\n",
       "           DR_CR  \n",
       "count   22546758  \n",
       "unique         2  \n",
       "top        Debit  \n",
       "freq    13871120  \n",
       "mean         NaN  \n",
       "std          NaN  \n",
       "min          NaN  \n",
       "25%          NaN  \n",
       "50%          NaN  \n",
       "75%          NaN  \n",
       "max          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC_ID</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>DOC_DATE</th>\n",
       "      <th>NARATION</th>\n",
       "      <th>DR_CR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3644877</td>\n",
       "      <td>342800.00</td>\n",
       "      <td>01-NOV-22</td>\n",
       "      <td>Cash Withdraw</td>\n",
       "      <td>Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1175256</td>\n",
       "      <td>342800.00</td>\n",
       "      <td>01-NOV-22</td>\n",
       "      <td>Cash Withdrawal From A/C No.:</td>\n",
       "      <td>Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2298226</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>01-NOV-22</td>\n",
       "      <td>Cash withdraw from Micro Merchant point, MM A/C</td>\n",
       "      <td>Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4066427</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>01-NOV-22</td>\n",
       "      <td>Credit Against Merchant Cash Withdraw Service ...</td>\n",
       "      <td>Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978564</td>\n",
       "      <td>2550.00</td>\n",
       "      <td>01-NOV-22</td>\n",
       "      <td>Cash withdraw from Micro Merchant point, MM A/C</td>\n",
       "      <td>Debit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AC_ID    AMOUNT   DOC_DATE   \n",
       "0  3644877 342800.00  01-NOV-22  \\\n",
       "1  1175256 342800.00  01-NOV-22   \n",
       "2  2298226   1500.00  01-NOV-22   \n",
       "3  4066427   1500.00  01-NOV-22   \n",
       "4  1978564   2550.00  01-NOV-22   \n",
       "\n",
       "                                            NARATION   DR_CR  \n",
       "0                                      Cash Withdraw   Debit  \n",
       "1                     Cash Withdrawal From A/C No.:   Credit  \n",
       "2   Cash withdraw from Micro Merchant point, MM A/C    Debit  \n",
       "3  Credit Against Merchant Cash Withdraw Service ...  Credit  \n",
       "4   Cash withdraw from Micro Merchant point, MM A/C    Debit  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AC_ID       category\n",
       "AMOUNT       float64\n",
       "DOC_DATE      object\n",
       "NARATION      object\n",
       "DR_CR         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "narration = df['NARATION']\n",
    "# remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "narration = narration.apply(lambda x: str(x).translate(translator))\n",
    "# narration.drop_duplicates().to_csv('narration_light_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-ascii characters\n",
    "narration = narration.apply(lambda x: re.sub('[^\\x00-\\x7F]+', ' ', str(x).strip()))\n",
    "narration.drop_duplicates().to_csv('narration_non_ascii_removed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128604\n"
     ]
    }
   ],
   "source": [
    "unique_narration = df['NARATION']\n",
    "unique_narration = unique_narration.drop_duplicates()\n",
    "print(len(unique_narration))\n",
    "# unique_narration.to_csv('narration.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shuaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shuaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shuaib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "stop_words = stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_narration(x):\n",
    "    x = str(x).lower().strip()\n",
    "    x = re.sub('[^a-zA-Z ]', ' ', x)\n",
    "    x = \" \".join(x.split())\n",
    "    words = word_tokenize(x)\n",
    "    words = [wnl.lemmatize(w) for w in words]\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_narration = unique_narration.apply(lambda x: clean_narration(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_narration.to_csv('narration_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128604, 30372)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the cleaned narration\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(unique_narration)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 214654.7047582739.\n",
      "Iteration 1, inertia 116919.86289339911.\n",
      "Iteration 2, inertia 115683.94508849054.\n",
      "Iteration 3, inertia 115177.08258791096.\n",
      "Iteration 4, inertia 115085.37968125037.\n",
      "Iteration 5, inertia 115042.18192299362.\n",
      "Iteration 6, inertia 115037.60311105319.\n",
      "Iteration 7, inertia 115037.4961278199.\n",
      "Iteration 8, inertia 115037.48350295007.\n",
      "Iteration 9, inertia 115037.48068617101.\n",
      "Iteration 10, inertia 115037.48002047653.\n",
      "Converged at iteration 10: strict convergence.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(max_iter=100, n_clusters=12, n_init=1, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(max_iter=100, n_clusters=12, n_init=1, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=12, n_init=1, verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 12\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " cheque\n",
      " ae\n",
      " withdrawal\n",
      " ad\n",
      " banking\n",
      " branch\n",
      " agent\n",
      "Cluster 1:\n",
      " eftn\n",
      " transaction\n",
      " bank\n",
      " ltd\n",
      " islami\n",
      " sonali\n",
      " bangladesh\n",
      "Cluster 2:\n",
      " deposit\n",
      " cash\n",
      " inter\n",
      " branch\n",
      " withdraw\n",
      " agent\n",
      " md\n",
      "Cluster 3:\n",
      " january\n",
      " salary\n",
      " month\n",
      " disbursement\n",
      " title\n",
      " rent\n",
      " allowance\n",
      "Cluster 4:\n",
      " transfer\n",
      " fund\n",
      " smart\n",
      " app\n",
      " regular\n",
      " cap\n",
      " dp\n",
      "Cluster 5:\n",
      " sme\n",
      " jamtoil\n",
      " dal\n",
      " pu\n",
      " male\n",
      " purush\n",
      " kornushuti\n",
      "Cluster 6:\n",
      " withdraw\n",
      " md\n",
      " transfer\n",
      " fund\n",
      " bazar\n",
      " loan\n",
      " islam\n",
      "Cluster 7:\n",
      " fee\n",
      " ctsu\n",
      " head\n",
      " usd\n",
      " office\n",
      " fvg\n",
      " citibank\n",
      "Cluster 8:\n",
      " salary\n",
      " month\n",
      " march\n",
      " credit\n",
      " november\n",
      " fvg\n",
      " february\n",
      "Cluster 9:\n",
      " dol\n",
      " mohila\n",
      " polli\n",
      " unnayan\n",
      " para\n",
      " polly\n",
      " unnoyon\n",
      "Cluster 10:\n",
      " bill\n",
      " cash\n",
      " net\n",
      " deposit\n",
      " month\n",
      " bidyut\n",
      " wifi\n",
      "Cluster 11:\n",
      " vgd\n",
      " cash\n",
      " deposit\n",
      " payment\n",
      " agent\n",
      " inter\n",
      " fund\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :7]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.1 GiB for an array with shape (128604, 30372) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mfit(X\u001b[39m.\u001b[39;49mtoarray())\n\u001b[0;32m      4\u001b[0m data2D \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(X\u001b[39m.\u001b[39mtoarray())\n\u001b[0;32m      5\u001b[0m labels \u001b[39m=\u001b[39m km\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[1;32ma:\\playground\\erainfo-tx-narration\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32ma:\\playground\\erainfo-tx-narration\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 29.1 GiB for an array with shape (128604, 30372) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "pca = PCA(n_components=2).fit(X.toarray())\n",
    "data2D = pca.transform(X.toarray())\n",
    "labels = km.labels_\n",
    "sns.scatterplot(data2D[:,0], data2D[:,1], hue=labels, palette=sns.color_palette(\"hls\", num_clusters))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erainfo-tx-narration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
